{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBA Career Prediction Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_label = 'xgb02f'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aim:\n",
    "* To improve on 0.71259 on Kaggle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings:\n",
    "\n",
    "Retain -ve values, apply SMOTE & under sampling pipeline, search on roc_auc.\n",
    "Results train, val auc:\n",
    "* (02a) SMOTE, under = 0.50, 0.75 : 0.98, 0.67. On Kaggle test = 0.66605. Terrible!\n",
    "* (02b) SMOTE in opt space (0.3), under = 1.0 : 0.96, 0.63\n",
    "* (02c) SMOTE in opt space (0.5), under = 0.75 : 0.81, 0.68\n",
    "* (02d) SMOTE 0.4 and under in opt space (0.7): 0.96, 0.67\n",
    "\n",
    "* (02e) bigger cv chunks? cv=5, SMOTE, under = 0.50, 0.75 : 0.72, 0.70.\n",
    "* (02f) cv=6 : 0.73, 0.69.\n",
    "* (02g) cv=4 :\n",
    "* (02h) cv=3 : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load  # simpler than pickle!\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "data_path = '../data/raw/uts-advdsi-nba-career-prediction'\n",
    "\n",
    "train_raw = pd.read_csv(data_path + '/train.csv')\n",
    "test_raw = pd.read_csv(data_path + '/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 22)\n",
      "(3799, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_old</th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10556</td>\n",
       "      <td>3799</td>\n",
       "      <td>80</td>\n",
       "      <td>24.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>45.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>72.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5342</td>\n",
       "      <td>3800</td>\n",
       "      <td>75</td>\n",
       "      <td>21.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>55.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5716</td>\n",
       "      <td>3801</td>\n",
       "      <td>85</td>\n",
       "      <td>19.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13790</td>\n",
       "      <td>3802</td>\n",
       "      <td>63</td>\n",
       "      <td>19.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5470</td>\n",
       "      <td>3803</td>\n",
       "      <td>63</td>\n",
       "      <td>17.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>50.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id_old    Id  GP   MIN   PTS  FGM  FGA   FG%  3P Made  3PA  ...  FTA   FT%  \\\n",
       "0   10556  3799  80  24.3   7.8  3.0  6.4  45.7      0.1  0.3  ...  2.9  72.1   \n",
       "1    5342  3800  75  21.8  10.5  4.2  7.9  55.1     -0.3 -1.0  ...  3.6  67.8   \n",
       "2    5716  3801  85  19.1   4.5  1.9  4.5  42.8      0.4  1.2  ...  0.6  75.7   \n",
       "3   13790  3802  63  19.1   8.2  3.5  6.7  52.5      0.3  0.8  ...  1.5  66.9   \n",
       "4    5470  3803  63  17.8   3.7  1.7  3.4  50.8      0.5  1.4  ...  0.5  54.0   \n",
       "\n",
       "   OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0   2.2   2.0  3.8  3.2  1.1  0.2  1.6            1  \n",
       "1   3.6   3.7  6.6  0.7  0.5  0.6  1.4            1  \n",
       "2   0.6   1.8  2.4  0.8  0.4  0.2  0.6            1  \n",
       "3   0.8   2.0  3.0  1.8  0.4  0.1  1.9            1  \n",
       "4   2.4   2.7  4.9  0.4  0.4  0.6  0.7            1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 1366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shapes & head\n",
    "\n",
    "print(train_raw.shape)\n",
    "print(test_raw.shape)\n",
    "\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_old</th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8194</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>19.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>75.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>33.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8196</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>44.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>70.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8197</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id_old  Id  GP   MIN   PTS  FGM   FGA   FG%  3P Made  3PA  ...  FTM  FTA  \\\n",
       "0       1   0  56   9.1   4.0  1.6   3.7  43.7      0.1  0.3  ...  0.7  1.2   \n",
       "1    8194   1  43  19.3  10.1  3.7   8.1  46.0      0.6  1.7  ...  1.8  2.5   \n",
       "2       3   2  82  33.9  11.3  4.9  10.6  45.6      0.5  1.9  ...  1.8  2.7   \n",
       "3    8196   3  86  44.7  18.8  6.8  15.9  42.9      0.5  1.8  ...  4.5  6.3   \n",
       "4    8197   4  58  12.3   4.7  1.6   4.0  40.0      0.5  1.7  ...  1.1  1.3   \n",
       "\n",
       "    FT%  OREB  DREB  REB  AST  STL  BLK  TOV  \n",
       "0  63.4   1.2   0.8  1.7  0.4  0.2  0.3  0.8  \n",
       "1  75.3   0.5   0.9  1.5  3.5  0.6  0.0  1.8  \n",
       "2  71.2   1.3   3.3  4.5  2.5  1.3  0.3  2.0  \n",
       "3  70.9   1.5   3.2  5.0  4.1  0.9  0.1  3.6  \n",
       "4  76.9   0.2   0.6  0.9  1.5  0.5 -0.4  0.9  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 22 columns):\n",
      "Id_old         8000 non-null int64\n",
      "Id             8000 non-null int64\n",
      "GP             8000 non-null int64\n",
      "MIN            8000 non-null float64\n",
      "PTS            8000 non-null float64\n",
      "FGM            8000 non-null float64\n",
      "FGA            8000 non-null float64\n",
      "FG%            8000 non-null float64\n",
      "3P Made        8000 non-null float64\n",
      "3PA            8000 non-null float64\n",
      "3P%            8000 non-null float64\n",
      "FTM            8000 non-null float64\n",
      "FTA            8000 non-null float64\n",
      "FT%            8000 non-null float64\n",
      "OREB           8000 non-null float64\n",
      "DREB           8000 non-null float64\n",
      "REB            8000 non-null float64\n",
      "AST            8000 non-null float64\n",
      "STL            8000 non-null float64\n",
      "BLK            8000 non-null float64\n",
      "TOV            8000 non-null float64\n",
      "TARGET_5Yrs    8000 non-null int64\n",
      "dtypes: float64(18), int64(4)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "# info\n",
    "train_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_old</th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6856.971000</td>\n",
       "      <td>7798.50000</td>\n",
       "      <td>62.777875</td>\n",
       "      <td>18.576662</td>\n",
       "      <td>7.267088</td>\n",
       "      <td>2.807037</td>\n",
       "      <td>6.231212</td>\n",
       "      <td>44.608900</td>\n",
       "      <td>0.264525</td>\n",
       "      <td>0.816562</td>\n",
       "      <td>...</td>\n",
       "      <td>1.947788</td>\n",
       "      <td>71.365825</td>\n",
       "      <td>1.077838</td>\n",
       "      <td>2.168500</td>\n",
       "      <td>3.245300</td>\n",
       "      <td>1.624513</td>\n",
       "      <td>0.648687</td>\n",
       "      <td>0.245212</td>\n",
       "      <td>1.257763</td>\n",
       "      <td>0.833625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3977.447579</td>\n",
       "      <td>2309.54541</td>\n",
       "      <td>17.118774</td>\n",
       "      <td>8.935263</td>\n",
       "      <td>4.318732</td>\n",
       "      <td>1.693373</td>\n",
       "      <td>3.584559</td>\n",
       "      <td>6.155453</td>\n",
       "      <td>0.384093</td>\n",
       "      <td>1.060964</td>\n",
       "      <td>...</td>\n",
       "      <td>1.252352</td>\n",
       "      <td>10.430447</td>\n",
       "      <td>0.785670</td>\n",
       "      <td>1.392224</td>\n",
       "      <td>2.085154</td>\n",
       "      <td>1.355986</td>\n",
       "      <td>0.407626</td>\n",
       "      <td>0.821037</td>\n",
       "      <td>0.723270</td>\n",
       "      <td>0.372440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3799.00000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>-3.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-17.900000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3413.750000</td>\n",
       "      <td>5798.75000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>40.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6787.500000</td>\n",
       "      <td>7798.50000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10299.250000</td>\n",
       "      <td>9798.25000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>48.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13798.000000</td>\n",
       "      <td>11798.00000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>73.800000</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>67.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>168.900000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id_old           Id           GP          MIN          PTS  \\\n",
       "count   8000.000000   8000.00000  8000.000000  8000.000000  8000.000000   \n",
       "mean    6856.971000   7798.50000    62.777875    18.576662     7.267088   \n",
       "std     3977.447579   2309.54541    17.118774     8.935263     4.318732   \n",
       "min        4.000000   3799.00000    -8.000000     2.900000     0.800000   \n",
       "25%     3413.750000   5798.75000    51.000000    12.000000     4.100000   \n",
       "50%     6787.500000   7798.50000    63.000000    16.800000     6.300000   \n",
       "75%    10299.250000   9798.25000    74.000000    23.500000     9.500000   \n",
       "max    13798.000000  11798.00000   123.000000    73.800000    34.200000   \n",
       "\n",
       "               FGM          FGA          FG%      3P Made          3PA  ...  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000  ...   \n",
       "mean      2.807037     6.231212    44.608900     0.264525     0.816562  ...   \n",
       "std       1.693373     3.584559     6.155453     0.384093     1.060964  ...   \n",
       "min       0.300000     0.800000    21.300000    -1.100000    -3.100000  ...   \n",
       "25%       1.600000     3.600000    40.400000     0.000000     0.100000  ...   \n",
       "50%       2.400000     5.400000    44.400000     0.300000     0.800000  ...   \n",
       "75%       3.700000     8.100000    48.700000     0.500000     1.500000  ...   \n",
       "max      13.100000    28.900000    67.200000     1.700000     4.700000  ...   \n",
       "\n",
       "               FTA          FT%         OREB         DREB          REB  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean      1.947788    71.365825     1.077838     2.168500     3.245300   \n",
       "std       1.252352    10.430447     0.785670     1.392224     2.085154   \n",
       "min       0.000000   -13.300000     0.000000     0.200000     0.300000   \n",
       "25%       1.000000    65.000000     0.500000     1.100000     1.700000   \n",
       "50%       1.700000    71.400000     0.900000     1.900000     2.800000   \n",
       "75%       2.600000    77.500000     1.500000     2.900000     4.300000   \n",
       "max      11.100000   168.900000     5.500000    11.000000    15.900000   \n",
       "\n",
       "               AST          STL          BLK          TOV  TARGET_5Yrs  \n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000  \n",
       "mean      1.624513     0.648687     0.245212     1.257763     0.833625  \n",
       "std       1.355986     0.407626     0.821037     0.723270     0.372440  \n",
       "min       0.000000     0.000000   -17.900000     0.100000     0.000000  \n",
       "25%       0.700000     0.300000     0.100000     0.700000     1.000000  \n",
       "50%       1.300000     0.600000     0.200000     1.100000     1.000000  \n",
       "75%       2.200000     0.900000     0.400000     1.600000     1.000000  \n",
       "max      12.800000     3.600000    18.900000     5.300000     1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 1369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#variable descriptions\n",
    "train_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_old</th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7010.614109</td>\n",
       "      <td>1899.000000</td>\n",
       "      <td>62.853909</td>\n",
       "      <td>18.650224</td>\n",
       "      <td>7.328034</td>\n",
       "      <td>2.835404</td>\n",
       "      <td>6.302580</td>\n",
       "      <td>44.599079</td>\n",
       "      <td>0.255962</td>\n",
       "      <td>0.796920</td>\n",
       "      <td>...</td>\n",
       "      <td>1.399842</td>\n",
       "      <td>1.953567</td>\n",
       "      <td>71.612924</td>\n",
       "      <td>1.096025</td>\n",
       "      <td>2.179495</td>\n",
       "      <td>3.275783</td>\n",
       "      <td>1.636483</td>\n",
       "      <td>0.653593</td>\n",
       "      <td>0.257726</td>\n",
       "      <td>1.257910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3954.173641</td>\n",
       "      <td>1096.821164</td>\n",
       "      <td>17.151740</td>\n",
       "      <td>8.727259</td>\n",
       "      <td>4.294724</td>\n",
       "      <td>1.688427</td>\n",
       "      <td>3.579221</td>\n",
       "      <td>6.040168</td>\n",
       "      <td>0.380987</td>\n",
       "      <td>1.052862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926140</td>\n",
       "      <td>1.250376</td>\n",
       "      <td>10.457336</td>\n",
       "      <td>0.785678</td>\n",
       "      <td>1.371935</td>\n",
       "      <td>2.070646</td>\n",
       "      <td>1.335496</td>\n",
       "      <td>0.410573</td>\n",
       "      <td>0.639660</td>\n",
       "      <td>0.712449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3644.000000</td>\n",
       "      <td>949.500000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7062.000000</td>\n",
       "      <td>1899.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>44.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10402.500000</td>\n",
       "      <td>2848.500000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13792.000000</td>\n",
       "      <td>3798.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>74.600000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>127.100000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>5.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id_old           Id           GP          MIN          PTS  \\\n",
       "count   3799.000000  3799.000000  3799.000000  3799.000000  3799.000000   \n",
       "mean    7010.614109  1899.000000    62.853909    18.650224     7.328034   \n",
       "std     3954.173641  1096.821164    17.151740     8.727259     4.294724   \n",
       "min        1.000000     0.000000     6.000000     3.700000     0.700000   \n",
       "25%     3644.000000   949.500000    51.000000    12.200000     4.200000   \n",
       "50%     7062.000000  1899.000000    63.000000    17.000000     6.400000   \n",
       "75%    10402.500000  2848.500000    74.000000    23.300000     9.400000   \n",
       "max    13792.000000  3798.000000   126.000000    68.000000    33.000000   \n",
       "\n",
       "               FGM          FGA          FG%      3P Made          3PA  ...  \\\n",
       "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000  ...   \n",
       "mean      2.835404     6.302580    44.599079     0.255962     0.796920  ...   \n",
       "std       1.688427     3.579221     6.040168     0.380987     1.052862  ...   \n",
       "min       0.300000     0.800000    25.100000    -1.000000    -2.700000  ...   \n",
       "25%       1.600000     3.700000    40.500000     0.000000     0.100000  ...   \n",
       "50%       2.500000     5.500000    44.600000     0.300000     0.800000  ...   \n",
       "75%       3.700000     8.100000    48.500000     0.500000     1.500000  ...   \n",
       "max      13.400000    26.200000    74.600000     1.600000     4.300000  ...   \n",
       "\n",
       "               FTM          FTA          FT%         OREB         DREB  \\\n",
       "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000   \n",
       "mean      1.399842     1.953567    71.612924     1.096025     2.179495   \n",
       "std       0.926140     1.250376    10.457336     0.785678     1.371935   \n",
       "min       0.000000     0.000000    23.700000     0.000000     0.200000   \n",
       "25%       0.700000     1.000000    65.000000     0.500000     1.200000   \n",
       "50%       1.200000     1.700000    71.500000     0.900000     1.900000   \n",
       "75%       1.900000     2.600000    78.000000     1.500000     2.900000   \n",
       "max       7.800000     9.800000   127.100000     6.900000    12.000000   \n",
       "\n",
       "               REB          AST          STL          BLK          TOV  \n",
       "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000  \n",
       "mean      3.275783     1.636483     0.653593     0.257726     1.257910  \n",
       "std       2.070646     1.335496     0.410573     0.639660     0.712449  \n",
       "min       0.300000     0.000000     0.000000    -7.100000     0.100000  \n",
       "25%       1.800000     0.600000     0.400000     0.100000     0.700000  \n",
       "50%       2.800000     1.300000     0.600000     0.200000     1.100000  \n",
       "75%       4.300000     2.300000     0.900000     0.400000     1.600000  \n",
       "max      18.500000     9.000000     2.700000    14.800000     5.200000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 1370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisions\n",
    "\n",
    "We will retain all potential features, when using non-linear models.\n",
    "\n",
    "and TARGET_5Yrs is our target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_raw.copy()\n",
    "test = test_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['Id_old', 'Id'] #, 'MIN', 'FGM', 'FGA', 'TOV', '3PA', 'FTM', 'FTA', 'REB']\n",
    "train.drop(cols_drop, axis=1, inplace=True)\n",
    "test.drop(cols_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>24.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>45.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>72.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>21.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>55.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>19.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>34.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>19.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>17.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>50.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN   PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0  80  24.3   7.8  3.0  6.4  45.7      0.1  0.3  22.6  2.0  2.9  72.1   2.2   \n",
       "1  75  21.8  10.5  4.2  7.9  55.1     -0.3 -1.0  34.9  2.4  3.6  67.8   3.6   \n",
       "2  85  19.1   4.5  1.9  4.5  42.8      0.4  1.2  34.3  0.4  0.6  75.7   0.6   \n",
       "3  63  19.1   8.2  3.5  6.7  52.5      0.3  0.8  23.7  0.9  1.5  66.9   0.8   \n",
       "4  63  17.8   3.7  1.7  3.4  50.8      0.5  1.4  13.7  0.2  0.5  54.0   2.4   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0   2.0  3.8  3.2  1.1  0.2  1.6            1  \n",
       "1   3.7  6.6  0.7  0.5  0.6  1.4            1  \n",
       "2   1.8  2.4  0.8  0.4  0.2  0.6            1  \n",
       "3   2.0  3.0  1.8  0.4  0.1  1.9            1  \n",
       "4   2.7  4.9  0.4  0.4  0.6  0.7            1  "
      ]
     },
     "execution_count": 1373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>19.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>35.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>75.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>33.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>44.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>44.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>70.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>38.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN   PTS  FGM   FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0  56   9.1   4.0  1.6   3.7  43.7      0.1  0.3   7.3  0.7  1.2  63.4   1.2   \n",
       "1  43  19.3  10.1  3.7   8.1  46.0      0.6  1.7  35.1  1.8  2.5  75.3   0.5   \n",
       "2  82  33.9  11.3  4.9  10.6  45.6      0.5  1.9  44.8  1.8  2.7  71.2   1.3   \n",
       "3  86  44.7  18.8  6.8  15.9  42.9      0.5  1.8  13.5  4.5  6.3  70.9   1.5   \n",
       "4  58  12.3   4.7  1.6   4.0  40.0      0.5  1.7  38.7  1.1  1.3  76.9   0.2   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TOV  \n",
       "0   0.8  1.7  0.4  0.2  0.3  0.8  \n",
       "1   0.9  1.5  3.5  0.6  0.0  1.8  \n",
       "2   3.3  4.5  2.5  1.3  0.3  2.0  \n",
       "3   3.2  5.0  4.1  0.9  0.1  3.6  \n",
       "4   0.6  0.9  1.5  0.5 -0.4  0.9  "
      ]
     },
     "execution_count": 1374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative values do not make sense in this context\n",
    "\n",
    "def clean_negatives(strategy, df):\n",
    "    \n",
    "    if strategy=='abs':\n",
    "        df = abs(df)\n",
    "    if strategy=='null':\n",
    "        df[df < 0] = None\n",
    "    if strategy=='mean':\n",
    "        df[df < 0] = None\n",
    "        df.fillna(df.mean(), inplace=True)      \n",
    "    \n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_strategy = ''\n",
    "\n",
    "train = clean_negatives(negatives_strategy, train)\n",
    "test = clean_negatives(negatives_strategy, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>24.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>45.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>72.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>21.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>55.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>19.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>34.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>19.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>17.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>50.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN   PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0  80  24.3   7.8  3.0  6.4  45.7      0.1  0.3  22.6  2.0  2.9  72.1   2.2   \n",
       "1  75  21.8  10.5  4.2  7.9  55.1     -0.3 -1.0  34.9  2.4  3.6  67.8   3.6   \n",
       "2  85  19.1   4.5  1.9  4.5  42.8      0.4  1.2  34.3  0.4  0.6  75.7   0.6   \n",
       "3  63  19.1   8.2  3.5  6.7  52.5      0.3  0.8  23.7  0.9  1.5  66.9   0.8   \n",
       "4  63  17.8   3.7  1.7  3.4  50.8      0.5  1.4  13.7  0.2  0.5  54.0   2.4   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0   2.0  3.8  3.2  1.1  0.2  1.6            1  \n",
       "1   3.7  6.6  0.7  0.5  0.6  1.4            1  \n",
       "2   1.8  2.4  0.8  0.4  0.2  0.6            1  \n",
       "3   2.0  3.0  1.8  0.4  0.1  1.9            1  \n",
       "4   2.7  4.9  0.4  0.4  0.6  0.7            1  "
      ]
     },
     "execution_count": 1377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>19.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>35.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>75.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>33.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>44.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>44.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>70.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>38.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN   PTS  FGM   FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0  56   9.1   4.0  1.6   3.7  43.7      0.1  0.3   7.3  0.7  1.2  63.4   1.2   \n",
       "1  43  19.3  10.1  3.7   8.1  46.0      0.6  1.7  35.1  1.8  2.5  75.3   0.5   \n",
       "2  82  33.9  11.3  4.9  10.6  45.6      0.5  1.9  44.8  1.8  2.7  71.2   1.3   \n",
       "3  86  44.7  18.8  6.8  15.9  42.9      0.5  1.8  13.5  4.5  6.3  70.9   1.5   \n",
       "4  58  12.3   4.7  1.6   4.0  40.0      0.5  1.7  38.7  1.1  1.3  76.9   0.2   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TOV  \n",
       "0   0.8  1.7  0.4  0.2  0.3  0.8  \n",
       "1   0.9  1.5  3.5  0.6  0.0  1.8  \n",
       "2   3.3  4.5  2.5  1.3  0.3  2.0  \n",
       "3   3.2  5.0  4.1  0.9  0.1  3.6  \n",
       "4   0.6  0.9  1.5  0.5 -0.4  0.9  "
      ]
     },
     "execution_count": 1378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train.pop('TARGET_5Yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:(8000, 19)\n",
      "test:(3799, 19)\n"
     ]
    }
   ],
   "source": [
    "#examine shapes\n",
    "\n",
    "print('train:' + str(train.shape))\n",
    "print('test:' + str(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 6669, 0: 1331})\n"
     ]
    }
   ],
   "source": [
    "# target class balance check\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(train_target)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformations\n",
    "\n",
    "# scaling - not for tree-based model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training data and validation data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, train_target, test_size=0.2, random_state=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.18.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "#import models\n",
    "\n",
    "!pip install xgboost\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.010518407212622\n"
     ]
    }
   ],
   "source": [
    "#Class balancing\n",
    "\n",
    "class_weight = counter[1.0] / counter[0.0]\n",
    "print(class_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "initial_model = xgb.XGBClassifier(#scale_pos_weight = class_weight,\n",
    "                                 use_label_encoder=False,\n",
    "                                 seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-index the y_train, since xgboost has deprecated the use_label_encoder function\n",
    "\n",
    "y_train.index = range(0, len(y_train), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:02:11] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=6, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 1388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "\n",
    "initial_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/aj_xgb02f_initial.joblib']"
      ]
     },
     "execution_count": 1389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(initial_model,  '../models/aj_' + experiment_label + '_initial.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = initial_model.predict(X_train)\n",
    "y_val_preds = initial_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.models.aj_metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "        pred:0  pred:1\n",
      "true:0     937     137\n",
      "true:1       0    5326\n",
      "Val:\n",
      "        pred:0  pred:1\n",
      "true:0      23     234\n",
      "true:1      64    1279\n"
     ]
    }
   ],
   "source": [
    "# Show TRAINING confusion matrix with labels\n",
    "\n",
    "print(\"Training:\")\n",
    "print(confusion_matrix(y_train, y_train_preds))\n",
    "\n",
    "print(\"Val:\")\n",
    "print(confusion_matrix(y_val, y_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93      1074\n",
      "           1       0.97      1.00      0.99      5326\n",
      "\n",
      "    accuracy                           0.98      6400\n",
      "   macro avg       0.99      0.94      0.96      6400\n",
      "weighted avg       0.98      0.98      0.98      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.09      0.13       257\n",
      "           1       0.85      0.95      0.90      1343\n",
      "\n",
      "    accuracy                           0.81      1600\n",
      "   macro avg       0.55      0.52      0.51      1600\n",
      "weighted avg       0.75      0.81      0.77      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, y_train_preds))\n",
    "print(metrics.classification_report(y_val, y_val_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe, hp, fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /opt/conda/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.7/site-packages (from imblearn) (0.7.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.18.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "# class imbalance pipeline\n",
    "\n",
    "!pip install imblearn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "      \n",
    "    xgboost = xgb.XGBClassifier(\n",
    "        max_depth = int(space['max_depth']),\n",
    "        learning_rate = space['learning_rate'],\n",
    "        min_child_weight = space['min_child_weight'],\n",
    "        gamma = space['gamma'],\n",
    "        subsample = space['subsample'],\n",
    "        colsample_bytree = space['colsample_bytree'],\n",
    "        #scale_pos_weight = space['scale_pos_weight'],\n",
    "        use_label_encoder=False,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Define model pipeline\n",
    "    model = Pipeline([\n",
    "        ('over', SMOTE(sampling_strategy=0.5)),\n",
    "        ('under', RandomUnderSampler(sampling_strategy=0.75)),\n",
    "        ('model', xgboost)\n",
    "    ])\n",
    "    \n",
    "    acc = cross_val_score(model, X_train, y_train, cv=6, scoring=\"roc_auc\").mean()\n",
    "\n",
    "    return{'loss': 1-acc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1397,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'max_depth' : hp.choice('max_depth', range(5, 20, 1)),\n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.05),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'gamma' : hp.quniform('gamma', 0, 0.1, 0.01),\n",
    "    'subsample' : hp.quniform('subsample', 0.1, 1, 0.05),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.05)\n",
    "    #'scale_pos_weight' : hp.quniform('scale_pos_weight', 1, class_weight, class_weight / 5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:02:13] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:13] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:14] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:14] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:14] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.69s/trial, best loss: 0.31962617664492354]\n"
     ]
    }
   ],
   "source": [
    "best = fmin(\n",
    "    fn=objective,   \n",
    "    space=space,       \n",
    "    algo=tpe.suggest,       \n",
    "    max_evals=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best:  {'colsample_bytree': 0.2, 'gamma': 0.03, 'learning_rate': 0.05, 'max_depth': 13, 'min_child_weight': 8.0, 'subsample': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: \", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:02:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('over', SMOTE(sampling_strategy=0.5)),\n",
       "                ('under', RandomUnderSampler(sampling_strategy=0.75)),\n",
       "                ('model',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=0.2, gamma=0.03, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='', learning_rate=0.05,\n",
       "                               max_delta_step=0, max_depth=13,\n",
       "                               min_child_weight=8.0, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=6, num_parallel_tree=1, random_state=42,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=42, subsample=0.1, tree_method='exact',\n",
       "                               use_label_encoder=False, validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 1400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### and here is where we take the best hyperparamters from the hyperparameter search and fit the model again.\n",
    "\n",
    "xgboost_2 = xgb.XGBClassifier(\n",
    "    max_depth = best['max_depth'],\n",
    "    learning_rate = best['learning_rate'],\n",
    "    min_child_weight = best['min_child_weight'],\n",
    "    gamma = best['gamma'],    \n",
    "    subsample = best['subsample'],\n",
    "    colsample_bytree = best['colsample_bytree'],\n",
    "    #scale_pos_weight = best['scale_pos_weight'],\n",
    "    use_label_encoder=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Define model pipeline\n",
    "best_model = Pipeline([\n",
    "    ('over', SMOTE(sampling_strategy=0.5)),\n",
    "    ('under', RandomUnderSampler(sampling_strategy=0.75)),\n",
    "    ('model', xgboost_2)\n",
    "])\n",
    "\n",
    "best_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/aj_xgb02f_best.joblib']"
      ]
     },
     "execution_count": 1401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model to file\n",
    "\n",
    "dump(best_model,  '../models/aj_' + experiment_label + '_best.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions for train & validation sets\n",
    "\n",
    "y_train_preds = best_model.predict(X_train)\n",
    "y_val_preds = best_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "        pred:0  pred:1\n",
      "true:0     491     583\n",
      "true:1     820    4506\n",
      "Val:\n",
      "        pred:0  pred:1\n",
      "true:0      93     164\n",
      "true:1     242    1101\n"
     ]
    }
   ],
   "source": [
    "# Show TRAINING confusion matrix with labels\n",
    "\n",
    "print(\"Training:\")\n",
    "print(confusion_matrix(y_train, y_train_preds))\n",
    "\n",
    "print(\"Val:\")\n",
    "print(confusion_matrix(y_val, y_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.46      0.41      1074\n",
      "           1       0.89      0.85      0.87      5326\n",
      "\n",
      "    accuracy                           0.78      6400\n",
      "   macro avg       0.63      0.65      0.64      6400\n",
      "weighted avg       0.80      0.78      0.79      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.36      0.31       257\n",
      "           1       0.87      0.82      0.84      1343\n",
      "\n",
      "    accuracy                           0.75      1600\n",
      "   macro avg       0.57      0.59      0.58      1600\n",
      "weighted avg       0.78      0.75      0.76      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, y_train_preds))\n",
    "print(metrics.classification_report(y_val, y_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "from sklearn import metrics\n",
    "metrics.plot_roc_curve(best_model, X_train, y_train)\n",
    "plt.show() \n",
    "metrics.plot_roc_curve(best_model, X_val, y_val)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply to test data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = best_model.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_probs = best_model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id': range(0,3799), 'TARGET_5Yrs': [p[1] for p in y_test_probs]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.491991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.660616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.788735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.836366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.551067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  TARGET_5Yrs\n",
       "0   0     0.491991\n",
       "1   1     0.660616\n",
       "2   2     0.788735\n",
       "3   3     0.836366\n",
       "4   4     0.551067"
      ]
     },
     "execution_count": 1409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../reports/aj_' + experiment_label + 'submission.csv',\n",
    "                 index=False,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
